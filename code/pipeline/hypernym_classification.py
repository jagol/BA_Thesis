import os
import json
import pickle
from random import shuffle, randint
from typing import *
# import numpy as np
from sklearn.svm import SVC
import embeddings


class HypernymClassifier:

    def __init__(self, path: str):
        """Initialize a hypernym classifier. Currently only svm
        classification is implemented.

        Args:
            path: The path to the output directory.
        """
        self.path = path
        self.clf = SVC(kernel='rbf', C=10, gamma=0.1, probability=True,
                       random_state=0)
        self.embedding_dict = embeddings.load_embedding_dict('combined')

    def train(self, X: List[List[float]], y: List[int]) -> None:
        """Train the hypernym classifier.

        Args:
            X: A numpy array containing the input data.
            y: The labels to be predicted. The have to be in the same
                order as the elements in X. A 1 indicates hypernymy,
                a 0 indicates, that there is no hypernymy.
        """
        self.clf.fit(X, y)

    def test(self, X, y):
        """Test the trained classifier. Return the mean accuracy.

        Args:
            X: The test samples.
            y: The test labels
        """

    def classify_prob(self, relations: List[List[float]]) -> List[float]:
        """Classify the given relations but return only probabilities.

        For each relation return the hypernym probability.

        Args:
            relations: A numpy array containing the relations. Each
                relation is expected to be again a numpy array of
                floats.
        """
        prob_distrs = self.clf.predict_proba(relations)
        hypernym_probs = [t[0] for t in prob_distrs]
        return hypernym_probs

    def save(self):
        """Save the model under in output dir 'hyp_clf.pickle'."""
        pickle.dump(self.clf, os.path.join(self.path, 'hyp_clf.pickle'))

    def load(self):
        """Load model from file."""
        self.clf = pickle.load(os.path.join(self.path, 'hyp_clf.pickle'))

    def get_train_rels(self, level: str) -> List[Tuple[str, str]]:
        """Get hypernym relation to train from file.

        Get the hypernym relations for training from
        'hierarchical_relations_{tokens/lemmas}.json'. The relations in
        this file have been extracted using Hearst Patterns.

        Args:
            level: 't' of tokens, 'l' if lemmas.
        """
        if level == 't':
            path = os.path.join(self.path,
                                'hierarchy/hierarchical_relations_tokens.json')
        elif level == 'l':
            path = os.path.join(self.path,
                                'hierarchy/hierarchical_relations_lemmas.json')

        with open(path, 'r', encoding='utf8') as f:
            rel_dict = json.load(f)
        relations = []
        for hyper in rel_dict:
            for hypo in rel_dict[hyper]:
                relations.append((hypo, hyper))
        return relations

    def generate_negative_examples(self,
                                   relations_pos: List[Tuple[str, str]],
                                   level: str
                                   ) -> List[Tuple[str, str]]:
        """Generate negative examples for training.

        Negative samples are generated by two processes:
        1: Generate negative examples by randomly choosing two terms
        from 'processed_corpus/{token/lemma}_terms.txt'. If the tuple
        consisting of those two terms is in the positive relations, it
        won't be used.
        2: For a positive sample, exchange the hyponym and the
        hypernym and use it as a negative sample.

        Twice the number of negative samples as there are positive
        samples are generated.

        Args:
            relations_pos: A list of positive samples. First hyponym,
                then hypernym.
            level: 't' of tokens, 'l' if lemmas.
        """
        relations_neg = []
        for rel in relations_pos:
            relations_neg.append((rel[1], rel[0]))

        if level == 't':
            path = os.path.join(self.path,
                                'processed_corpus/{token/lemma}_terms.txt')
        elif level == 'l':
            path = os.path.join(self.path,
                                'processed_corpus/{token/lemma}_terms.txt')

        terms = set()
        with open(path, 'r', encoding='utf8') as f:
            for line in f:
                terms.add(line.strip('\n'))

        len_pos = len(relations_pos)
        # Store tuples of indices (ints) of chosen relations.
        chosen_relations = set()
        num_neg_samples = 0

        while num_neg_samples < len_pos:
            ri1 = randint(0, len_pos-1)
            ri2 = randint(0, len_pos-1)
            sample_idx = (ri1, ri2)
            if sample_idx not in chosen_relations:
                sample = (terms[ri1], terms[ri2])
                if sample not in relations_pos:
                    relations_neg.append(sample)
                    chosen_relations.add(sample_idx)
        return relations_neg

    def get_rel_embeddings(self,
                           rels: List[Tuple[str, str]]
                           ) -> List[Tuple[List[float]]]:
        """Get embeddings for the given relations.

        Args:
            rels: The relations, first hyponym, then hypernym.
        """
        rel_embs = []
        for rel in rels:
            hypo, hyper = rel[0], rel[1]
            hypo_emb = self.embedding_dict[hypo]
            hyper_emb = self.embedding_dict[hyper]
            rel_embs.append((hypo_emb, hyper_emb))
        return rel_embs

    def get_training_data(self, level):
        """Get and prepare the data for the hypernym classifier.

        Args:
            level: 't' of tokens, 'l' if lemmas.
        """
        relations_pos = self.get_train_rels(level)
        relations_neg = self.generate_negative_examples(relations_pos, level)
        rel_embs_pos = self.get_rel_embeddings(relations_pos)
        rel_embs_neg = self.get_rel_embeddings(relations_neg)
        labeled_pos = [(t, 1) for t in rel_embs_pos]
        labeled_neg = [(t, 0) for t in rel_embs_neg]

        # Generate the same number of negative examples as there are
        # positive examples.

        data = shuffle(labeled_pos + labeled_neg)
        # Use 90 Percent for training and 10% for testing
        train_test_split = 9*(len(data/10))
        train_data = data[:train_test_split]
        test_data = data[train_test_split:]
        return train_data, test_data


def train_hypernym_classifier(path: str, level: str):
    """Train a hypernym classifier.

    Args:
        level: 't' of tokens, 'l' if lemmas.
    """
    print('Prepare training data...')
    clf = HypernymClassifier(path)
    print('Read relations from file and generate negative sampels...')
    train_data, test_data = clf.get_training_data('l')
    train_samples = [t[0] for t in train_data]
    train_labels = [t[1] for t in train_data]
    test_samples = [t[0] for t in test_data]
    test_labels = [t[1] for t in test_data]
    clf.train(train_samples, train_labels)
    print('Accuracy:', clf.test(test_samples, test_labels))
    clf.save()


if __name__ == '__main__':
    train_hypernym_classifier('./output/dblp/', 'l')
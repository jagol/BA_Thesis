import os
import json
import pickle
from random import shuffle, randint
from typing import *
import numpy as np
from sklearn.svm import SVC
from embeddings import Embeddings
from utility_functions import get_config, get_cmd_args


class HypernymClassifier:

    def __init__(self, path: str):
        """Initialize a hypernym classifier. Currently only svm
        classification is implemented.

        Args:
            path: The path to the output directory.
        """
        # Set paths.
        self.path = path
        self.path_idx_to_term = os.path.join(
            path_out, 'indexing/idx_to_token.json')
        self.path_term_to_idx = os.path.join(
            path_out, 'indexing/token_to_idx.json')
        self.path_embs = os.path.join(
            path_out, 'embeddings/embs_token_global_Word2Vec.vec')
        self.path_hearst = os.path.join(
            path_out, 'hierarchy/hierarch_rels_tokens_idx.json')

        # Load data.
        with open(self.path_idx_to_term, 'r', encoding='utf8') as f:
            self.idx_to_term = {int(k): v for k, v in json.load(f).items()}
        with open(self.path_term_to_idx, 'r', encoding='utf8') as f:
            self.term_to_idx = json.load(f)
        with open(self.path_hearst, 'r', encoding='utf8') as f:
            self.hearst = {int(k): v for k, v in json.load(f).items()}
        self.term_ids = set(self.hearst.keys())
        for k in self.hearst:
            hypos = self.hearst[k]
            self.term_ids = self.term_ids.union(set(hypos))
        self.embedding_dict = Embeddings.load_term_embeddings(
            self.term_ids, self.path_embs, self.idx_to_term)

        # Instanciate classifier.
        self.clf = SVC(kernel='rbf', C=10, gamma=0.1, probability=True,
                       random_state=0)

    def train(self, x: List[List[float]], y: List[int]) -> None:
        """Train the hypernym classifier.

        Args:
            x: A numpy array containing the input data.
            y: The labels to be predicted. The have to be in the same
                order as the elements in X. A 1 indicates hypernymy,
                a 0 indicates, that there is no hypernymy.
        """
        self.clf.fit(x, y)

    def test(self, x, y):
        """Test the trained classifier. Return the mean accuracy.

        Args:
            x: The test samples.
            y: The test labels
        """
        pass

    def classify_prob(self, relations: np.ndarray) -> List[float]:
        """Classify the given relations but return only probabilities.

        For each relation return the hypernym probability.

        Args:
            relations: A numpy array containing the relations. Each
                relation is expected to be again a numpy array of
                floats.
        """
        prob_distrs = self.clf.predict_proba(relations)
        hypernym_probs = [t[0] for t in prob_distrs]
        return hypernym_probs

    def save(self):
        """Save the model under in hierarchy dir 'hyp_clf.pickle'."""
        pickle.dump(self.clf, os.path.join(
            self.path, 'hierarchy/hyp_clf.pickle'))

    def load(self):
        """Load model from file."""
        self.clf = pickle.load(os.path.join(
            self.path, 'hierarchy/hyp_clf.pickle'))

    def get_pos_rels(self) -> List[Tuple[int, int]]:
        """Get hypernym relation to train from file.

        Get the hypernym relations for training from
        'hierarchical_relations_tokens.json'. The relations in
        this file have been extracted using Hearst Patterns.
        """
        # path = os.path.join(self.path,
        #                     'hierarchy/hierarchical_relations_tokens.json')
        #
        # with open(path, 'r', encoding='utf8') as f:
        #     rel_dict = json.load(f)
        relations = []
        for hyper in self.hearst:
            for hypo in self.hearst[hyper]:
                relations.append((hypo, hyper))
        return relations

    def get_neg_rels(self,
                     relations_pos: List[Tuple[int, int]],
                     ) -> List[Tuple[int, int]]:
        """Generate negative examples for training.

        Negative samples are generated by two processes:
        1: Generate negative examples by randomly choosing two terms
        from 'processed_corpus/{token/lemma}_terms.txt'. If the tuple
        consisting of those two terms is in the positive relations, it
        won't be used.
        2: For a positive sample, exchange the hyponym and the
        hypernym and use it as a negative sample.

        Twice the number of negative samples as there are positive
        samples are generated.

        Args:
            relations_pos: A list of positive samples. First hyponym-idx,
                then hypernym-idx.
        """
        relations_neg = []
        for rel in relations_pos:
            relations_neg.append((rel[1], rel[0]))

        path = os.path.join(
            self.path, 'processed_corpus/token_term_idxs.txt')

        terms = set()
        with open(path, 'r', encoding='utf8') as f:
            for line in f:
                terms.add(line.strip('\n'))

        len_pos = len(relations_pos)
        # Store tuples of indices (ints) of chosen relations.
        rand_chosen_relations = set()

        while len(rand_chosen_relations) < len_pos:
            ri1 = randint(0, len_pos-1)
            ri2 = randint(0, len_pos-1)
            sample_idx = (ri1, ri2)
            if sample_idx not in rand_chosen_relations:
                if sample_idx not in relations_pos:
                    rand_chosen_relations.add(sample_idx)

        relations_neg.extend(rand_chosen_relations)

        return relations_neg

    def get_rel_embeddings(self,
                           rels: List[Tuple[int, int]]
                           ) -> List[Tuple[np.array, np.array]]:
        """Get embeddings for the given relations.

        Args:
            rels: The relations, first hyponym, then hypernym.
        """
        rel_embs = []
        for rel in rels:
            hypo, hyper = rel[0], rel[1]
            hypo_emb = self.embedding_dict[hypo]
            hyper_emb = self.embedding_dict[hyper]
            rel_embs.append((hypo_emb, hyper_emb))
        return rel_embs

    @staticmethod
    def get_rel_embs_diff(relations_embs: List[Tuple[np.ndarray, np.ndarray]]
                          ) -> List[np.ndarray]:
        """Get the difference between hypernym and hyponym embedding.

        Args:
            relations_embs: A list of tuples. Each tuple is of the form:
                (hyponym-embedding, hypernym-embedding)
        """
        embs_diff = []
        for hypo_emb, hyper_emb in relations_embs:
            embs_diff.append(hypo_emb-hyper_emb)
        return embs_diff

    def get_training_data(self):
        """Get and prepare the data for the hypernym classifier."""
        pos_rels = self.get_pos_rels()
        neg_rels = self.get_neg_rels(pos_rels)
        rel_embs_pos = self.get_rel_embeddings(pos_rels)
        rel_embs_neg = self.get_rel_embeddings(neg_rels)
        rel_embs_pos_diff = self.get_rel_embs_diff(rel_embs_pos)
        rel_embs_neg_diff = self.get_rel_embs_diff(rel_embs_neg)
        labeled_pos = [(t, 1) for t in rel_embs_pos_diff]
        labeled_neg = [(t, 0) for t in rel_embs_neg_diff]

        # Generate the same number of negative examples as there are
        # positive examples.

        data = shuffle(labeled_pos + labeled_neg)
        # Use 90 Percent for training and 10% for testing
        train_test_split = 9*(len(data/10))
        train_data = data[:train_test_split]
        test_data = data[train_test_split:]
        return train_data, test_data


def train_hypernym_classifier(path: str):
    """Train a hypernym classifier."""
    print('Prepare training data...')
    clf = HypernymClassifier(path)
    print('Read relations from file and generate negative sampels...')
    train_data, test_data = clf.get_training_data()
    train_samples = [t[0] for t in train_data]
    train_labels = [t[1] for t in train_data]
    test_samples = [t[0] for t in test_data]
    test_labels = [t[1] for t in test_data]
    clf.train(train_samples, train_labels)
    print('Accuracy:', clf.test(test_samples, test_labels))
    clf.save()


if __name__ == '__main__':
    config = get_config()
    args = get_cmd_args()
    path_out = config['paths'][args.location][args.corpus]['path_out']
    train_hypernym_classifier(path_out)
